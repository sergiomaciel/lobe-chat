# Proxy, if you need it
# HTTP_PROXY=http://localhost:7890
# HTTPS_PROXY=http://localhost:7890


# Other environment variables, as needed. You can refer to the environment variables configuration for the client version, making sure not to have ACCESS_CODE.
OPENAI_API_KEY=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
# OPENAI_PROXY_URL=https://api.openai.com/v1
# OPENAI_MODEL_LIST=...

# ===========================
# ====== Preset config ====== 
# ===========================
# if no special requirements, no need to change
LOBE_PORT=3210
CASDOOR_PORT=8000
MINIO_PORT=9000

# Postgres related, which are the necessary environment variables for DB
LOBE_DB_NAME=lobechat
POSTGRES_PASSWORD=uWNZugjBqixf8dxC

# Casdoor secret
AUTH_CASDOOR_ID=a387a4892ee19b1a2249
AUTH_CASDOOR_SECRET=dbf205949d704de81b0b5b3603174e23fbecc354

# MinIO S3 configuration
MINIO_ROOT_USER=YOUR_MINIO_USER
MINIO_ROOT_PASSWORD=YOUR_MINIO_PASSWORD

# Configure the bucket information of MinIO
MINIO_LOBE_BUCKET=lobe
S3_ACCESS_KEY_ID=soaucnP8Bip0TDdUjxng
S3_SECRET_ACCESS_KEY=ZPUzvY34umfcfxvWKSv0P00vczVMB6YmgJS5J9eO

# Ollama
# https://lobehub.com/es/docs/self-hosting/examples/ollama
# https://github.com/ollama/ollama/blob/main/docs/linux.md
OLLAMA_PROXY_URL=http://host.docker.internal:11434